# -*- coding: utf-8 -*-
"""
å‘é‡å­˜å‚¨æœåŠ¡æ¨¡å— (é‡æ„ç‰ˆ)
æ­¤ç‰ˆæœ¬ä½¿ç”¨ RAGDatabaseManager æ¥ç®¡ç†æ–‡æ¡£å’Œç´¢å¼•ï¼Œ
å¹¶ä½¿ç”¨ query_and_find_topk è¿›è¡ŒæŸ¥è¯¢ã€‚
"""
import os
import shutil
from typing import List, Optional, Dict, Any
import logging
import concurrent.futures
import functools
# å¯¼å…¥æ–°çš„ç®¡ç†å™¨å’ŒæŸ¥è¯¢å‡½æ•°
# å‡è®¾è¿™äº›åœ¨åŒä¸€ä¸ªé¡¹ç›®æˆ–å¯é€šè¿‡ PYTHONPATH æ‰¾åˆ°
# from .rag_database_manager import RAGDatabaseManager # å¦‚æœåœ¨åŒ…å†…
# from .query_topk import query_and_find_topk # å¦‚æœåœ¨åŒ…å†…
# å¦åˆ™ï¼Œæ ¹æ®å®é™…æ–‡ä»¶ç»“æ„è°ƒæ•´å¯¼å…¥è·¯å¾„ï¼Œä¾‹å¦‚ï¼š
from services.build_database import RAGDatabaseManager  # å‡è®¾ build_database.py åœ¨åŒä¸€ç›®å½•æˆ–å·²å¯¼å…¥
from services.get_top_from_rag import query_and_find_topk # å‡è®¾ get_top_from_rag.py åœ¨åŒä¸€ç›®å½•æˆ–å·²å¯¼å…¥

# --- é…ç½®æ—¥å¿— ---
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class VectorStoreService:
    """
    å‘é‡å­˜å‚¨æœåŠ¡ç±»ï¼Œç”¨äºç®¡ç†æ–‡æ¡£å‘é‡å­˜å‚¨ (é‡æ„ç‰ˆ)
    è¯¥ç‰ˆæœ¬å§”æ‰˜ RAGDatabaseManager å¤„ç†å­˜å‚¨å’Œç´¢å¼•ï¼Œä½¿ç”¨ query_and_find_topk è¿›è¡ŒæŸ¥è¯¢ã€‚
    """

    # 1. åˆå§‹åŒ–å‘é‡å­˜å‚¨æœåŠ¡
    def __init__(self, index_dir: str = "faiss_index", rag_working_dir: str = "./rag_storage"):
        """
        index_dir - ä¸ºäº†å…¼å®¹æ€§ä¿ç•™ï¼Œä½†ä¸»è¦ä½¿ç”¨ rag_working_dir
        rag_working_dir - RAG ç³»ç»Ÿçš„å·¥ä½œç›®å½•ï¼ŒåŒ…å« vdb_chunks.json ç­‰
        """
        self.rag_working_dir = rag_working_dir
        self.index_dir = index_dir  # ä¿ç•™ä»¥å…¼å®¹æ—§æ¥å£ï¼Œä½†å®é™…ä¸ç”¨
        self.vdb_chunks_path = os.path.join(self.rag_working_dir, "vdb_chunks.json")

        # åˆå§‹åŒ– RAGDatabaseManager
        self.db_manager = RAGDatabaseManager(working_dir=self.rag_working_dir)
        # æ·»åŠ ä¸€ä¸ªå±æ€§æ¥æŒ‡ç¤ºæœåŠ¡æ˜¯å¦å·²å‡†å¤‡å¥½ (ä¾‹å¦‚ï¼Œç´¢å¼•æ–‡ä»¶æ˜¯å¦å­˜åœ¨)
        self.is_ready = False
        # åœ¨åˆå§‹åŒ–æ—¶æ£€æŸ¥ä¸€æ¬¡
        self.load_vector_store()
        logger.info(f"VectorStoreService initialized with RAG working dir: {self.rag_working_dir}")

    # 2. æ›´æ–°åµŒå…¥æ¨¡å‹ (æ­¤ç‰ˆæœ¬ä¸å†éœ€è¦ï¼Œå› ä¸ºç”± RAGDatabaseManager å†…éƒ¨ç®¡ç†)
    def update_embedding_model(self, model_name: str) -> bool:
        """
        æ­¤ç‰ˆæœ¬ä¸ç›´æ¥æ”¯æŒåŠ¨æ€æ›´æ–°åµŒå…¥æ¨¡å‹ã€‚
        æ¨¡å‹é…ç½®åº”åœ¨ RAGDatabaseManager åˆå§‹åŒ–æ—¶ç¡®å®šã€‚
        @return å§‹ç»ˆè¿”å› Falseï¼Œè¡¨ç¤ºæœªæ‰§è¡Œæ›´æ–°ã€‚
        """
        logger.warning("update_embedding_model is not supported in this version. Configure model in RAGDatabaseManager.")
        return False

    # 3. æ–‡æœ¬åˆ†å—æ–¹æ³• (æ­¤ç‰ˆæœ¬ä¸å†éœ€è¦ï¼Œå› ä¸ºç”± RAGDatabaseManager å†…éƒ¨å¤„ç†)
    def split_documents(self, documents: List[Any]) -> List[Any]:
        """
        æ­¤ç‰ˆæœ¬ä¸ç›´æ¥æä¾›æ–‡æœ¬åˆ†å—åŠŸèƒ½ã€‚
        åˆ†å—ç”± RAGDatabaseManager åœ¨å¤„ç†æ–‡æ¡£æ—¶å†…éƒ¨å®Œæˆã€‚
        @return ç›´æ¥è¿”å›åŸå§‹ documentsã€‚
        """
        logger.warning("split_documents is handled internally by RAGDatabaseManager.")
        return documents

    # 4. åˆ›å»ºå…¨æ–°çš„å‘é‡åº“å®ä¾‹ (ä½¿ç”¨ RAGDatabaseManager)
    async def create_vector_store(self, document_paths: List[str]) -> bool:
        """
        ä½¿ç”¨ RAGDatabaseManager é‡æ–°æ„å»ºå‘é‡åº“ã€‚
        document_paths - æœ¬åœ°æ–‡æ¡£æ–‡ä»¶è·¯å¾„åˆ—è¡¨ (PDF, DOCX, etc.)
        @return æ˜¯å¦åˆ›å»º/é‡å»ºæˆåŠŸ
        """
        if not document_paths:
            logger.warning("æ²¡æœ‰æ–‡æ¡£è·¯å¾„å¯ä»¥åˆ›å»ºå‘é‡å­˜å‚¨")
            # æ›´æ–°çŠ¶æ€
            self.is_ready = False
            return False

        logger.info(f"å¼€å§‹é€šè¿‡ RAGDatabaseManager é‡æ–°æ„å»ºå‘é‡å­˜å‚¨ï¼Œæ–‡æ¡£æ•°é‡: {len(document_paths)}")

        try:
            # ä½¿ç”¨ RAGDatabaseManager é‡å»ºæ•°æ®åº“
            # è¿™ä¼šæ¸…ç©ºç°æœ‰æ•°æ®å¹¶æ·»åŠ æ–°æ–‡æ¡£
            success = await self.db_manager.add_documents(document_paths)

            if success:
                logger.info("å‘é‡å­˜å‚¨ (é€šè¿‡ RAGDatabaseManager) é‡å»ºæˆåŠŸ")
                # æ›´æ–°çŠ¶æ€
                self.is_ready = True
            else:
                logger.error("å‘é‡å­˜å‚¨ (é€šè¿‡ RAGDatabaseManager) é‡å»ºå¤±è´¥")
                # æ›´æ–°çŠ¶æ€
                self.is_ready = False
            return success

        except Exception as e:
            logger.error(f"é€šè¿‡ RAGDatabaseManager åˆ›å»º/é‡å»ºå‘é‡å­˜å‚¨å¤±è´¥: {str(e)}", exc_info=True)
            # æ›´æ–°çŠ¶æ€
            self.is_ready = False
            return False

    # 5. ä¿å­˜å‘é‡å­˜å‚¨ (æ­¤åŠŸèƒ½ç”± RAGDatabaseManager å†…éƒ¨è‡ªåŠ¨å¤„ç†)
    def _save_vector_store(self):
        """
        æ­¤ç‰ˆæœ¬ä¸­ï¼Œä¿å­˜ç”± RAGDatabaseManager è‡ªåŠ¨å¤„ç†ã€‚
        """
        logger.info("å‘é‡å­˜å‚¨çš„ä¿å­˜ç”± RAGDatabaseManager è‡ªåŠ¨å¤„ç†ã€‚")

    # 6. åŠ è½½å‘é‡å­˜å‚¨ (æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§å¹¶è®¾ç½® is_ready)
    def load_vector_store(self) -> bool:
        """
        æ£€æŸ¥å‘é‡å­˜å‚¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œä»¥ç¡®å®šæ˜¯å¦å·²åŠ è½½æˆ–å¯åŠ è½½ã€‚
        @return bool: å¦‚æœæ£€æµ‹åˆ°å‘é‡å­˜å‚¨æ–‡ä»¶åˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
        """
        # æ£€æŸ¥æ ¸å¿ƒçš„ vdb_chunks.json æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if os.path.exists(self.vdb_chunks_path):
            logger.info(f"æ£€æµ‹åˆ°å‘é‡å­˜å‚¨æ–‡ä»¶: {self.vdb_chunks_path}")
            # æ›´æ–°çŠ¶æ€
            self.is_ready = True
            return True  # è¿”å› True è¡¨ç¤ºå·²å‡†å¤‡å¥½
        else:
            logger.warning(f"æœªæ£€æµ‹åˆ°å‘é‡å­˜å‚¨æ–‡ä»¶: {self.vdb_chunks_path}")
            # æ›´æ–°çŠ¶æ€
            self.is_ready = False
            return False  # è¿”å› False è¡¨ç¤ºæœªå‡†å¤‡å¥½

    # 7. æœç´¢ç›¸å…³æ–‡æ¡£ (æ ¸å¿ƒåŠŸèƒ½ï¼Œä½¿ç”¨æ–°çš„ query_and_find_topk)
    async def search_documents(self, query: str, top_k: int = 3, threshold: float = 0.0) -> List[Dict[str, Any]]:
        """
        query - æŸ¥è¯¢æ–‡æœ¬
        top_k - è¿”å›çš„ top K ä¸ªç»“æœ
        threshold - ç›¸ä¼¼åº¦é˜ˆå€¼ (åœ¨ query_and_find_topk ä¸­å¯èƒ½éœ€è¦è°ƒæ•´å¤„ç†)

        @return ç›¸å…³æ–‡æ¡£ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« 'content', 'file_path', 'similarity' ç­‰
                å¦‚æœå‘ç”Ÿé”™è¯¯æˆ–æœªæ‰¾åˆ°ï¼Œåˆ™è¿”å›ç©ºåˆ—è¡¨ã€‚
        """
        # æ£€æŸ¥å‘é‡å­˜å‚¨æ˜¯å¦å·²å‡†å¤‡å¥½
        if not self.is_ready:
            logger.warning("å‘é‡å­˜å‚¨æœªå‡†å¤‡å¥½ï¼Œæ— æ³•è¿›è¡Œæœç´¢")
            return []

        # æ£€æŸ¥å‘é‡å­˜å‚¨æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆåŒé‡ä¿é™©ï¼‰
        if not os.path.exists(self.vdb_chunks_path):
            logger.warning("å‘é‡å­˜å‚¨æ–‡ä»¶ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œæœç´¢")
            # çŠ¶æ€å¯èƒ½ä¸åŒæ­¥ï¼Œæ›´æ–°ä¸€ä¸‹
            self.is_ready = False
            return []

        try:
            logger.info(f"å¼€å§‹æœç´¢ä¸ '{query}' ç›¸å…³çš„æ–‡æ¡£...")

            # --- å…³é”®ï¼šè°ƒç”¨æ–°çš„æŸ¥è¯¢å‡½æ•° ---
            # æ³¨æ„ï¼šè¿™è¦æ±‚ query_and_find_topk å·²è¢«ä¿®æ”¹ä»¥è¿”å›ç»“æ„åŒ–æ•°æ®
            # è€Œä¸æ˜¯ä»…ä»…æ‰“å°ç»“æœã€‚
            # å¦‚æœ query_and_find_topk ä»ç„¶åªæ‰“å°ï¼Œè¯·å‚è€ƒä¹‹å‰çš„å›ç­”ä¿®æ”¹å®ƒã€‚
            results = await query_and_find_topk(query, self.vdb_chunks_path, top_k)
            # print(results)

            # ç¡®ä¿è¿”å›çš„æ˜¯åˆ—è¡¨
            if not isinstance(results, list):
                 logger.error(f"query_and_find_topk è¿”å›äº†æ„å¤–çš„ç±»å‹: {type(results)}")
                 return []

            # æ ¹æ®é˜ˆå€¼è¿‡æ»¤ç»“æœ (å¦‚æœéœ€è¦)
            # æ³¨æ„ï¼šquery_and_find_topk å†…éƒ¨è®¡ç®—çš„æ˜¯ä½™å¼¦ç›¸ä¼¼åº¦ï¼ŒèŒƒå›´ [0, 1] (é€šå¸¸)
            # threshold=0.0 æ„å‘³ç€è¿”å›æ‰€æœ‰ç»“æœ
            if threshold > 0.0:
                filtered_results = [res for res in results if res.get('similarity', 1.0) >= threshold]
                logger.info(f"æœç´¢å®Œæˆï¼Œè¿”å› {len(filtered_results)} ä¸ªç›¸å…³æ–‡æ¡£ (é˜ˆå€¼: {threshold})")
                return filtered_results
            else:
                logger.info(f"æœç´¢å®Œæˆï¼Œè¿”å› {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
                return results

        except Exception as e:
            logger.error(f"æœç´¢æ–‡æ¡£å¤±è´¥: {str(e)}", exc_info=True)
            return []

    # 8. è·å–æ–‡æ¡£ä¸Šä¸‹æ–‡ (ä¿æŒä¸å˜ï¼Œå¤„ç† search_documents çš„è¾“å‡º)
    def get_context(self, docs: List[Dict[str, Any]]) -> str:
        """
        docs - ç”± search_documents è¿”å›çš„æ–‡æ¡£å­—å…¸åˆ—è¡¨

        @return åˆå¹¶åçš„ä¸Šä¸‹æ–‡
        """
        if not docs:
            return ""
        # å‡è®¾æ¯ä¸ª doc å­—å…¸éƒ½æœ‰ 'content' é”®
        return "\n\n".join(doc.get('content', '') for doc in docs)

    # 9. æ·»åŠ å•ä¸ªæ–‡æ¡£åˆ°å‘é‡å­˜å‚¨ (ä½¿ç”¨ RAGDatabaseManager)
    async def add_document(self, document_path: str, metadata: Dict[str, Any] = None) -> bool:
        """
        æ·»åŠ å•ä¸ªæ–‡æ¡£åˆ°å‘é‡å­˜å‚¨ (é€šè¿‡ RAGDatabaseManager)

        @param {str} document_path - æ–‡æ¡£æ–‡ä»¶è·¯å¾„ (PDF, DOCX, etc.)
        @param {Dict[str, Any]} metadata - æ–‡æ¡£å…ƒæ•°æ® (å¯é€‰ï¼Œç”± RAGDatabaseManager å¤„ç†)
        @return {bool} æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        if not document_path or not os.path.exists(document_path):
            logger.warning(f"æ–‡æ¡£è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨: '{document_path}'")
            return False

        try:
            logger.info(f"å¼€å§‹æ·»åŠ æ–‡æ¡£: {document_path}")

            # ä½¿ç”¨ RAGDatabaseManager æ·»åŠ å•ä¸ªæ–‡æ¡£
            # æ³¨æ„ï¼šç¡®ä¿ RAGDatabaseManager.add_document è¿”å›å¸ƒå°”å€¼
            success = await self.db_manager.add_document(document_path)

            if success:
                logger.info(f"æˆåŠŸæ·»åŠ æ–‡æ¡£: {document_path}")
                # æ·»åŠ æ–‡æ¡£åï¼Œç´¢å¼•åº”è¯¥å·²æ›´æ–°ï¼Œæ ‡è®°ä¸ºå°±ç»ª
                self.is_ready = True
            else:
                logger.error(f"æ·»åŠ æ–‡æ¡£å¤±è´¥: {document_path}")
            return success

        except Exception as e:
            logger.error(f"æ·»åŠ æ–‡æ¡£ '{document_path}' å¤±è´¥: {str(e)}", exc_info=True)
            return False

    # 10. æ¸…é™¤ç´¢å¼• (ä½¿ç”¨ RAGDatabaseManager çš„é€»è¾‘æˆ–ç›´æ¥åˆ é™¤æ–‡ä»¶)
    def clear_index(self):
        """
        æ¸…é™¤ç´¢å¼• (é€šè¿‡ RAGDatabaseManager æˆ–ç›´æ¥æ–‡ä»¶æ“ä½œ)
        """
        try:
            # æ–¹æ³•ä¸€ï¼šç›´æ¥åˆ é™¤ rag_working_dir ä¸‹çš„ç›¸å…³æ–‡ä»¶
            # è¿™æ˜¯æœ€ç›´æ¥å’Œå½»åº•çš„æ–¹æ³•
            if os.path.exists(self.rag_working_dir):
                shutil.rmtree(self.rag_working_dir)
                logger.info(f"ç´¢å¼•ç›®å½• '{self.rag_working_dir}' å·²æ¸…é™¤")
                # é‡æ–°åˆ›å»ºç©ºç›®å½•
                os.makedirs(self.rag_working_dir, exist_ok=True)
                # é‡æ–°åˆå§‹åŒ– db_manager å®ä¾‹
                self.db_manager = RAGDatabaseManager(working_dir=self.rag_working_dir)
                logger.info("å·²é‡æ–°åˆå§‹åŒ– RAGDatabaseManager")
            else:
                logger.warning(f"ç´¢å¼•ç›®å½• '{self.rag_working_dir}' ä¸å­˜åœ¨")

            # æ¸…é™¤åï¼ŒçŠ¶æ€å˜ä¸ºæœªå‡†å¤‡å¥½
            self.is_ready = False

        except Exception as e:
            logger.error(f"æ¸…é™¤ç´¢å¼•å¤±è´¥: {str(e)}", exc_info=True)
            # å³ä½¿å‡ºé”™ï¼Œä¹Ÿå¯èƒ½è®¤ä¸ºç´¢å¼•çŠ¶æ€ä¸ç¡®å®šï¼Œè®¾ä¸º False
            self.is_ready = False
            raise # é‡æ–°æŠ›å‡ºå¼‚å¸¸ä»¥ä¾¿è°ƒç”¨è€…å¤„ç†

    # --- å…¼å®¹æ€§å±æ€§ (ä¾›æ—§ç‰ˆ UI æ£€æŸ¥) ---
    @property
    def vector_store(self):
        """
        å…¼å®¹æ€§å±æ€§ï¼šä¸ºæ—§ç‰ˆ UI æä¾›æ£€æŸ¥ç‚¹ã€‚
        å¦‚æœæœåŠ¡å·²å‡†å¤‡å¥½ (is_ready=True)ï¼Œåˆ™è¿”å›ä¸€ä¸ªé None çš„å ä½ç¬¦å¯¹è±¡ã€‚
        å¦åˆ™è¿”å› Noneã€‚
        """
        # æ³¨æ„ï¼šè¿™ä¸ªå ä½ç¬¦å¯¹è±¡ä¸åº”è¯¥è¢«å®é™…è°ƒç”¨å…¶æ–¹æ³•
        # å®ƒä»…ä»…æ˜¯ä¸ºäº†è®© `if not vector_store.vector_store:` è¿™æ ·çš„æ£€æŸ¥é€šè¿‡æˆ–å¤±è´¥
        if self.is_ready:
            # è¿”å›ä¸€ä¸ªç®€å•çš„é None å¯¹è±¡ä½œä¸ºå ä½ç¬¦
            return lambda: None # æˆ–è€… object() æˆ– type('Placeholder', (), {})()
        else:
            return None

# --- ç¤ºä¾‹ç”¨æ³• (å¦‚æœéœ€è¦ç›´æ¥è¿è¡Œæ­¤ç±») ---
# æ³¨æ„ï¼šè¿™éœ€è¦ query_and_find_topk è¿”å›ç»“æ„åŒ–æ•°æ®
"""
import asyncio
import os

async def example_usage():
    # --- åˆå§‹åŒ–æœåŠ¡ ---
    vss = VectorStoreService(rag_working_dir="./rag_storage")

    # --- æ£€æŸ¥/åŠ è½½ç´¢å¼• ---
    is_loaded = vss.load_vector_store() # ç”±å†…éƒ¨å¤„ç†ï¼Œè¿™é‡Œæ£€æŸ¥è¿”å›å€¼
    print(f"Vector Store Loaded: {is_loaded}")

    # --- æ·»åŠ æ–‡æ¡£ (å¦‚æœç´¢å¼•ä¸ºç©ºæˆ–éœ€è¦æ›´æ–°) ---
    # documents_to_add = [
    #     r"D:\adavance\tsy\rag4chat\test.pdf",
    #     # r"D:\adavance\tsy\rag4chat\test2.docx"
    # ]
    # success = await vss.create_vector_store(documents_to_add) # é‡å»º
    # print(f"Create Vector Store Success: {success}")
    # æˆ–è€…æ·»åŠ å•ä¸ªæ–‡æ¡£
    # success = await vss.add_document(r"D:\adavance\tsy\rag4chat\test.pdf")
    # print(f"Add Document Success: {success}")

    # --- æŸ¥è¯¢ ---
    query_text = "è¯­ä¹‰å›¾åƒå¦‚ä½•æ„å»ºï¼Ÿ"
    topk = 5
    threshold = 0.1 # è®¾ç½®ä¸€ä¸ªåˆç†çš„é˜ˆå€¼

    if not os.getenv("DASHSCOPE_API_KEY"):
        print("âŒ é”™è¯¯: ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æœªè®¾ç½®ã€‚è¯·è®¾ç½®åé‡è¯•ã€‚")
        return

    print(f"ğŸ” æ­£åœ¨æœç´¢ä¸ '{query_text}' ç›¸å…³çš„æ–‡æ¡£...")
    results = await vss.search_documents(query_text, top_k=topk, threshold=threshold)

    print(f"ğŸ“„ æœç´¢ç»“æœ ({len(results)} ä¸ª):")
    for i, res in enumerate(results):
        print(f"--- ç»“æœ {i+1} (ç›¸ä¼¼åº¦: {res.get('similarity', 'N/A'):.4f}) ---")
        print(f"  å†…å®¹é¢„è§ˆ: {res.get('content', 'N/A')[:100]}...")
        print(f"  æ–‡ä»¶è·¯å¾„: {res.get('file_path', 'N/A')}")
        print(f"  Chunk ID: {res.get('chunk_id', 'N/A')}")
        print("-" * 20)

    context = vss.get_context(results)
    print(f"ğŸ§¾ åˆå¹¶ä¸Šä¸‹æ–‡é¢„è§ˆ:\\n{context[:200]}...")

if __name__ == "__main__":
    asyncio.run(example_usage())
"""