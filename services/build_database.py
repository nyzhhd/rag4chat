import asyncio
import aiohttp
import base64
from typing import List, Dict, Any, Optional
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.utils import EmbeddingFunc
import os
import shutil
import logging
import numpy as np
import json


# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

import asyncio
import base64
from typing import List, Dict, Any, Optional
from raganything import RAGAnything, RAGAnythingConfig
from lightrag.utils import EmbeddingFunc
import os
import shutil
import logging
import json

# =======================
# æ–°å¢ï¼šå¯¼å…¥ AsyncOpenAI
# =======================
from openai import AsyncOpenAI

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)



# å¦‚æœè¦ä½¿ç”¨ rerankï¼Œéœ€è¦å®‰è£… sentence-transformers
try:
    from sentence_transformers import CrossEncoder
    RERANK_AVAILABLE = True
except ImportError:
    RERANK_AVAILABLE = False


# =======================
# å·¥å…·å‡½æ•°ï¼šè°ƒç”¨ Ollama APIï¼ˆå¼‚æ­¥ï¼‰
# =======================
async def bailian_embed_async(texts: List[str], model: str = "text-embedding-v4") -> List[List[float]]:
    """
    å¼‚æ­¥è°ƒç”¨é˜¿é‡Œäº‘ç™¾ç‚¼ Embedding API (text-embedding-v4)
    ä½¿ç”¨ OpenAI å…¼å®¹æ¥å£
    """
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        raise ValueError("ç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æœªè®¾ç½®")

    # åˆå§‹åŒ–å¼‚æ­¥å®¢æˆ·ç«¯
    client = AsyncOpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
    )

    embeddings = []
    target_dim = 1024  # text-embedding-v4 æ”¯æŒ dimensions=1024

    for i, text_item in enumerate(texts):
        # --- 1. ç±»å‹æ£€æŸ¥å’Œé¢„å¤„ç† ---
        if not isinstance(text_item, str):
            if text_item is None:
                logger.warning(f"bailian_embed_async: æ–‡æœ¬ {i} æ˜¯ Noneï¼Œå°†å…¶è½¬æ¢ä¸ºç©ºå­—ç¬¦ä¸²ã€‚")
                text = ""
            else:
                logger.warning(f"bailian_embed_async: æ–‡æœ¬ {i} ç±»å‹ä¸º {type(text_item)}, å°è¯•è½¬æ¢ä¸ºå­—ç¬¦ä¸²ã€‚")
                text = str(text_item)
        else:
            text = text_item

        # å¤„ç†ç©ºå­—ç¬¦ä¸²æˆ–çº¯ç©ºç™½å­—ç¬¦ä¸²
        if not text or not text.strip():
            logger.debug(f"bailian_embed_async: æ–‡æœ¬ {i} ä¸ºç©ºï¼Œè¿”å›é›¶å‘é‡ã€‚")
            embeddings.append([0.0] * target_dim)
            continue

        # --- 2. å‘é€è¯·æ±‚ ---
        try:
            response = await client.embeddings.create(
                model=model,
                input=text,
                dimensions=target_dim,        # æŒ‡å®šç»´åº¦
                encoding_format="float"       # è¿”å› float åˆ—è¡¨
            )
            # --- 3. è§£æå“åº” ---
            embedding = response.data[0].embedding  # è·å–åµŒå…¥å‘é‡

            if not isinstance(embedding, list):
                logger.error(f"bailian_embed_async: åµŒå…¥å‘é‡ä¸æ˜¯åˆ—è¡¨ (æ–‡æœ¬ {i})")
                embeddings.append([0.0] * target_dim)
                continue

            current_dim = len(embedding)

            if current_dim != target_dim:
                logger.warning(f"bailian_embed_async: åµŒå…¥ç»´åº¦ä¸åŒ¹é… (æ–‡æœ¬ {i}): æœŸæœ› {target_dim}, å®é™… {current_dim}")
                # å¡«å……æˆ–æˆªæ–­åˆ° 1024 ç»´
                if current_dim > target_dim:
                    embedding = embedding[:target_dim]
                else:
                    embedding.extend([0.0] * (target_dim - current_dim))

            # æ£€æŸ¥æ•°å€¼æœ‰æ•ˆæ€§
            import math
            if any(math.isnan(x) or math.isinf(x) for x in embedding):
                logger.error(f"bailian_embed_async: åµŒå…¥å‘é‡åŒ…å« NaN æˆ– Inf (æ–‡æœ¬ {i})")
                embeddings.append([0.0] * target_dim)
                continue

            embeddings.append(embedding)
            logger.debug(f"bailian_embed_async: æˆåŠŸä¸ºæ–‡æœ¬ {i} ç”Ÿæˆ {len(embedding)} ç»´åµŒå…¥ã€‚")

        except Exception as e:
            logger.error(f"è°ƒç”¨ ç™¾ç‚¼ Embedding API æ—¶å‘ç”Ÿé”™è¯¯ (æ–‡æœ¬ {i}): {e}", exc_info=True)
            embeddings.append([0.0] * target_dim)

    return embeddings

async def ollama_complete_async(
    model: str,
    prompt: str,
    system_prompt: Optional[str] = None,
    history_messages: List[Dict[str, str]] = [],
    **kwargs
) -> str:
    """
    å¼‚æ­¥è°ƒç”¨ Ollama (é€‚ç”¨äºæ–‡æœ¬ LLM)ï¼Œæ”¯æŒæ–‡æœ¬è¾“å…¥
    """
    messages = []

    if system_prompt:
        messages.append({"role": "system", "content": system_prompt})

    for msg in history_messages:
        messages.append({"role": msg["role"], "content": msg["content"]})

    messages.append({"role": "user", "content": prompt})

    payload = {
        "model": model,
        "messages": messages,
        "stream": False,
    }

    async with aiohttp.ClientSession() as session:
        async with session.post("http://localhost:11434/v1/chat/completions", json=payload) as resp:
            if resp.status != 200:
                text = await resp.text()
                raise Exception(f"Ollama LLM error {resp.status}: {text}")
            result = await resp.json()
            return result["choices"][0]["message"]["content"]


async def ollama_vision_complete_async(
    model: str,
    prompt: str,
    image_data: str,  # Base64 encoded image string
    **kwargs
) -> str:
    """
    å¼‚æ­¥è°ƒç”¨ Ollama è§†è§‰æ¨¡å‹ (å¦‚ Llava)ï¼Œæ”¯æŒå›¾åƒ + æ–‡æœ¬è¾“å…¥
    ä½¿ç”¨ /api/generate ç«¯ç‚¹
    """
    # æ„å»º payloadï¼Œç¬¦åˆ Ollama è§†è§‰æ¨¡å‹çš„è¦æ±‚
    payload = {
        "model": model,
        "prompt": prompt,
        "images": [image_data],  # å›¾åƒæ•°æ®ä½œä¸ºåˆ—è¡¨ä¼ é€’
        "stream": False,
    }

    async with aiohttp.ClientSession() as session:
        async with session.post("http://localhost:11434/api/generate", json=payload) as resp:
            if resp.status != 200:
                text = await resp.text()
                raise Exception(f"Ollama Vision Model error {resp.status}: {text}")
            result = await resp.json()
            # è§†è§‰æ¨¡å‹çš„å“åº”ç›´æ¥åœ¨ 'response' å­—æ®µ
            return result.get("response", "")


# =======================
# å¼‚æ­¥åµŒå…¥å‡½æ•°åŒ…è£…å™¨ï¼ˆæ›´æ–°ä¸ºä½¿ç”¨ bailianï¼‰
# =======================
class AsyncEmbeddingWrapper:
    def __init__(self, model: str = "text-embedding-v4"):
        self.model = model

    async def embed(self, texts: List[str]) -> List[List[float]]:
        return await bailian_embed_async(texts, self.model)


# =======================
# Rerank å‡½æ•°ï¼ˆå¯é€‰ï¼‰
# =======================

rerank_model_func = None
if RERANK_AVAILABLE:
    try:
        _reranker = CrossEncoder("BAAI/bge-reranker-base")

        def rerank_model_func(query: str, docs: List[str]) -> List[str]:
            if not docs:
                return []
            pairs = [(query, doc) for doc in docs]
            scores = _reranker.predict(pairs)
            ranked = sorted(zip(docs, scores), key=lambda x: x[1], reverse=True)
            return [doc for doc, _ in ranked]
    except Exception as e:
        logger.warning(f"Rerank model initialization failed: {e}")
        rerank_model_func = None


# =======================
# æ•°æ®åº“æ„å»ºå’Œæ›´æ–°å‡½æ•°æ¥å£
# =======================

class RAGDatabaseManager:
    """RAG æ•°æ®åº“ç®¡ç†å™¨ - ä¸“é—¨è´Ÿè´£æ•°æ®åº“æ„å»ºå’Œæ›´æ–°"""

    def __init__(
        self,
        working_dir: str = "./rag_storage",
        output_dir: str = "./output",
        llm_model: str = "qwen3:8b",
        embed_model: str = "text-embedding-v4",
        vision_model: str = "llava:latest",
        parser: str = "mineru"
    ):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        Args:
            working_dir: RAG å­˜å‚¨ç›®å½•
            output_dir: è¾“å‡ºç›®å½•
            llm_model: LLM æ¨¡å‹åç§°
            embed_model: åµŒå…¥æ¨¡å‹åç§°
            vision_model: è§†è§‰æ¨¡å‹åç§°
            parser: æ–‡æ¡£è§£æå™¨
        """
        self.working_dir = working_dir
        self.output_dir = output_dir
        self.llm_model = llm_model
        self.embed_model = embed_model
        self.vision_model = vision_model
        self.parser = parser
        # åˆ›å»ºåµŒå…¥åŒ…è£…å™¨å®ä¾‹
        self.embedding_wrapper = AsyncEmbeddingWrapper(self.embed_model)
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.working_dir, exist_ok=True)
        os.makedirs(self.output_dir, exist_ok=True)

    async def _create_rag_instance(self):
        """åˆ›å»º RAG å®ä¾‹"""

        # åˆ›å»ºé…ç½®
        config = RAGAnythingConfig(
            working_dir=self.working_dir,
            parser=self.parser,
            parse_method="auto",
            enable_image_processing=True, # ä¿æŒå¯ç”¨å›¾åƒå¤„ç†
            enable_table_processing=True,
            enable_equation_processing=True,
        )

        # LLM å‡½æ•°ï¼ˆå¼‚æ­¥ï¼‰- ç”¨äºæ–‡æœ¬å¤„ç†
        async def llm_model_func(prompt, system_prompt=None, history_messages=[], **kwargs):
            return await ollama_complete_async(
                model=self.llm_model,
                prompt=prompt,
                system_prompt=system_prompt,
                history_messages=history_messages,
                **kwargs
            )

        # è§†è§‰æ¨¡å‹å‡½æ•°ï¼ˆå¼‚æ­¥ï¼‰- ç”¨äºå›¾åƒå¤„ç†ï¼Œä½¿ç”¨æ–°çš„è§†è§‰æ¨¡å‹ API
        async def vision_model_func(
            prompt,
            system_prompt=None, # æ³¨æ„ï¼šOllava çš„ /api/generate å¯èƒ½ä¸ç›´æ¥æ”¯æŒ system prompt
            history_messages=[], # æ³¨æ„ï¼šOllava çš„ /api/generate å¯èƒ½ä¸ç›´æ¥æ”¯æŒå†å²æ¶ˆæ¯
            image_data=None,
            **kwargs
        ):
            # å¦‚æœæä¾›äº†å›¾åƒæ•°æ®ï¼Œåˆ™è°ƒç”¨è§†è§‰æ¨¡å‹
            if image_data:
                # å¯ä»¥åœ¨è¿™é‡Œç»„åˆ prompt å’Œ system_prompt å¦‚æœéœ€è¦
                # ä½†æ ‡å‡†çš„ /api/generate æ¥å£å¯èƒ½ä¸åŒºåˆ†å®ƒä»¬
                full_prompt = prompt
                if system_prompt:
                    full_prompt = f"{system_prompt}\n\n{prompt}"

                return await ollama_vision_complete_async(
                    model=self.vision_model,
                    prompt=full_prompt,
                    image_data=image_data,
                    **kwargs
                )
            else:
                # å¦‚æœæ²¡æœ‰å›¾åƒæ•°æ®ï¼Œå›é€€åˆ°æ™®é€š LLM
                return await llm_model_func(prompt, system_prompt, history_messages, **kwargs)

        # åµŒå…¥å‡½æ•°ï¼ˆçœŸæ­£çš„å¼‚æ­¥å‡½æ•°ï¼‰
        async def async_embedding_func(texts: List[str]) -> List[List[float]]:
            # è¿‡æ»¤ç©ºæ–‡æœ¬
            filtered_texts = [text if text.strip() else " " for text in texts]
            return await self.embedding_wrapper.embed(filtered_texts)

        # åµŒå…¥å‡½æ•°åŒ…è£…æˆ EmbeddingFunc æ ¼å¼
        embedding_func = EmbeddingFunc(
            embedding_dim=1024,  #  1024 ç»´
            max_token_size=512,  # æ”¯æŒé•¿æ–‡æœ¬
            func=async_embedding_func,
        )
        # === æ·»åŠ è¿™ä¸‰è¡Œï¼Œå°†å‡½æ•°ä¿å­˜ä¸ºå®ä¾‹å±æ€§ ===
        self.llm_model_func = llm_model_func
        self.vision_model_func = vision_model_func
        self.embedding_func = embedding_func

        # åˆå§‹åŒ– RAGAnything å‚æ•°
        rag_args = {
            "config": config,
            "llm_model_func": llm_model_func,
            "vision_model_func": vision_model_func, # ä½¿ç”¨ä¿®æ”¹åçš„è§†è§‰æ¨¡å‹å‡½æ•°
            "embedding_func": embedding_func,
        }

        # åªæœ‰åœ¨æ”¯æŒçš„æƒ…å†µä¸‹æ‰æ·»åŠ  rerank_model_func
        if rerank_model_func is not None:
            try:
                rag = RAGAnything(**rag_args, rerank_model_func=rerank_model_func)
            except TypeError:
                logger.warning("Current RAGAnything version doesn't support rerank_model_func, initializing without it")
                rag = RAGAnything(**rag_args)
        else:
            rag = RAGAnything(**rag_args)
        return rag

    async def add_document(
        self,
        file_path: str,
        parse_method: str = "auto"
    ) -> bool:
        """
        å‘æ•°æ®åº“æ·»åŠ å•ä¸ªæ–‡æ¡£
        Args:
            file_path: æ–‡æ¡£è·¯å¾„
            parse_method: è§£ææ–¹æ³•
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(file_path):
            logger.error(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return False
        # è·å–æ–‡ä»¶æ‰©å±•å
        file_extension = os.path.splitext(file_path)[1].lower()
        supported_extensions = ['.pdf', '.docx', '.doc', '.txt', '.md']
        if file_extension not in supported_extensions:
            logger.warning(f"æ–‡ä»¶æ ¼å¼å¯èƒ½ä¸æ”¯æŒ: {file_extension}, å°†å°è¯•å¤„ç†")
        try:
            # åˆ›å»º RAG å®ä¾‹
            rag = await self._create_rag_instance()
            logger.info(f"ğŸš€ å¼€å§‹å¤„ç†æ–‡æ¡£: {file_path}")
            await rag.process_document_complete(
                file_path=file_path,
                output_dir=self.output_dir,
                parse_method=parse_method
            )
            logger.info(f"âœ… æ–‡æ¡£å¤„ç†å®Œæˆ: {file_path}")
            return True
        except Exception as e:
            logger.error(f"âŒ æ–‡æ¡£å¤„ç†å¤±è´¥: {file_path}, é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            return False

    async def add_documents(
        self,
        file_paths: List[str],
        parse_method: str = "auto"
    ) -> Dict[str, bool]:
        """
        æ‰¹é‡å‘æ•°æ®åº“æ·»åŠ å¤šä¸ªæ–‡æ¡£
        Args:
            file_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
            parse_method: è§£ææ–¹æ³•
        Returns:
            Dict[str, bool]: æ¯ä¸ªæ–‡æ¡£çš„å¤„ç†ç»“æœ
        """
        results = {}
        for file_path in file_paths:
            results[file_path] = await self.add_document(file_path, parse_method)
        return results

    async def rebuild_database(
        self,
        file_paths: List[str],
        clear_existing: bool = True
    ) -> bool:
        """
        é‡æ–°æ„å»ºæ•°æ®åº“ï¼ˆå¯é€‰æ¸…é™¤ç°æœ‰æ•°æ®ï¼‰
        Args:
            file_paths: è¦æ·»åŠ çš„æ–‡æ¡£è·¯å¾„åˆ—è¡¨
            clear_existing: æ˜¯å¦æ¸…é™¤ç°æœ‰æ•°æ®
        Returns:
            bool: æ˜¯å¦æˆåŠŸé‡å»º
        """
        try:
            # å¦‚æœéœ€è¦æ¸…é™¤ç°æœ‰æ•°æ®
            if clear_existing and os.path.exists(self.working_dir):
                import shutil
                shutil.rmtree(self.working_dir)
                os.makedirs(self.working_dir, exist_ok=True)
                logger.info("ğŸ§¹ å·²æ¸…ç†ç°æœ‰æ•°æ®åº“")
            # æ‰¹é‡æ·»åŠ æ–‡æ¡£
            results = await self.add_documents(file_paths)
            # æ£€æŸ¥ç»“æœ
            success_count = sum(1 for success in results.values() if success)
            total_count = len(results)
            logger.info(f"ğŸ“Š æ•°æ®åº“é‡å»ºå®Œæˆ: {success_count}/{total_count} ä¸ªæ–‡æ¡£æˆåŠŸå¤„ç†")
            return success_count == total_count
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“é‡å»ºå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return False

    def get_database_info(self) -> Dict[str, Any]:
        """
        è·å–æ•°æ®åº“ä¿¡æ¯
        Returns:
            Dict: æ•°æ®åº“ä¿¡æ¯
        """
        info = {
            "working_dir": self.working_dir,
            "output_dir": self.output_dir,
            "models": {
                "llm": self.llm_model,
                "embedding": self.embed_model,
                "vision": self.vision_model
            }
        }
        # ç»Ÿè®¡å­˜å‚¨æ–‡ä»¶
        if os.path.exists(self.working_dir):
            files = os.listdir(self.working_dir)
            info["storage_files"] = files
            info["document_count"] = len([f for f in files if f.endswith('.json')])
        else:
            info["storage_files"] = []
            info["document_count"] = 0
        return info


# =======================
# ä¾¿æ·å‡½æ•°æ¥å£
# =======================

async def add_document_to_rag(
    file_path: str,
    working_dir: str = "./rag_storage",
    output_dir: str = "./output",
    **kwargs
) -> bool:
    """
    å‘ RAG æ•°æ®åº“æ·»åŠ å•ä¸ªæ–‡æ¡£ï¼ˆå¼‚æ­¥æ¥å£ï¼‰
    Args:
        file_path: æ–‡æ¡£è·¯å¾„
        working_dir: æ•°æ®åº“å­˜å‚¨ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        **kwargs: å…¶ä»–å‚æ•°ï¼ˆllm_model, embed_model, vision_model, parserï¼‰
    Returns:
        bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
    """
    manager = RAGDatabaseManager(
        working_dir=working_dir,
        output_dir=output_dir,
        **kwargs
    )
    return await manager.add_document(file_path)


async def add_documents_to_rag(
    file_paths: List[str],
    working_dir: str = "./rag_storage",
    output_dir: str = "./output",
    **kwargs
) -> Dict[str, bool]:
    """
    æ‰¹é‡å‘ RAG æ•°æ®åº“æ·»åŠ æ–‡æ¡£ï¼ˆå¼‚æ­¥æ¥å£ï¼‰
    Args:
        file_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
        working_dir: æ•°æ®åº“å­˜å‚¨ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        **kwargs: å…¶ä»–å‚æ•°
    Returns:
        Dict[str, bool]: æ¯ä¸ªæ–‡æ¡£çš„å¤„ç†ç»“æœ
    """
    manager = RAGDatabaseManager(
        working_dir=working_dir,
        output_dir=output_dir,
        **kwargs
    )
    return await manager.add_documents(file_paths)


async def rebuild_rag_database(
    file_paths: List[str],
    working_dir: str = "./rag_storage",
    output_dir: str = "./output",
    clear_existing: bool = True,
    **kwargs
) -> bool:
    """
    é‡æ–°æ„å»º RAG æ•°æ®åº“ï¼ˆå¼‚æ­¥æ¥å£ï¼‰
    Args:
        file_paths: æ–‡æ¡£è·¯å¾„åˆ—è¡¨
        working_dir: æ•°æ®åº“å­˜å‚¨ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        clear_existing: æ˜¯å¦æ¸…é™¤ç°æœ‰æ•°æ®
        **kwargs: å…¶ä»–å‚æ•°
    Returns:
        bool: æ˜¯å¦æˆåŠŸé‡å»º
    """
    manager = RAGDatabaseManager(
        working_dir=working_dir,
        output_dir=output_dir,
        **kwargs
    )
    return await manager.rebuild_database(file_paths, clear_existing)


# =======================
# åŒæ­¥æ¥å£
# =======================

def add_document_sync(
    file_path: str,
    working_dir: str = "./rag_storage",
    output_dir: str = "./output",
    **kwargs
) -> bool:
    """åŒæ­¥æ¥å£ï¼šæ·»åŠ å•ä¸ªæ–‡æ¡£"""
    return asyncio.run(add_document_to_rag(file_path, working_dir, output_dir, **kwargs))


def add_documents_sync(
    file_paths: List[str],
    working_dir: str = "./rag_storage",
    output_dir: str = "./output",
    **kwargs
) -> Dict[str, bool]:
    """åŒæ­¥æ¥å£ï¼šæ‰¹é‡æ·»åŠ æ–‡æ¡£"""
    return asyncio.run(add_documents_to_rag(file_paths, working_dir, output_dir, **kwargs))


def rebuild_database_sync(
    file_paths: List[str],
    working_dir: str = "./rag_storage",
    output_dir: str = "./output",
    clear_existing: bool = True,
    **kwargs
) -> bool:
    """åŒæ­¥æ¥å£ï¼šé‡æ–°æ„å»ºæ•°æ®åº“"""
    return asyncio.run(rebuild_rag_database(file_paths, working_dir, output_dir, clear_existing, **kwargs))


# =======================
# ä½¿ç”¨ç¤ºä¾‹
# =======================

async def main():
    # åˆ›å»ºæ•°æ®åº“ç®¡ç†å™¨
    db_manager = RAGDatabaseManager(
        working_dir="./rag_storage",
        output_dir="./output"
    )
    # ç¤ºä¾‹1: æ·»åŠ å•ä¸ªæ–‡æ¡£
    # pdf_path = r"D:\adavance\tsy\rag4chat\test.pdf"
    # success = await db_manager.add_document(pdf_path)
    # # print(f"æ·»åŠ æ–‡æ¡£ç»“æœ: {success}")

    # ç¤ºä¾‹2: æ‰¹é‡æ·»åŠ æ–‡æ¡£
    documents = [
        r"D:\adavance\tsy\rag4chat\knowladge2.docx",
        r"D:\adavance\tsy\rag4chat\knowladge3.docx",
        r"D:\adavance\tsy\rag4chat\knowladge4.docx",
        # r"D:\adavance\tsy\rag4chat\test.md" # å¦‚æœæœ‰å…¶ä»–æ–‡æ¡£
    ]
    results = await db_manager.add_documents(documents)
    print(f"æ‰¹é‡æ·»åŠ ç»“æœ: {results}")

    # # # ç¤ºä¾‹3: è·å–æ•°æ®åº“ä¿¡æ¯
    # info = db_manager.get_database_info()
    # print(f"æ•°æ®åº“ä¿¡æ¯: {info}")

    # # ç¤ºä¾‹4: é‡æ–°æ„å»ºæ•°æ®åº“
    # rebuild_success = await db_manager.rebuild_database(documents, clear_existing=True)
    # print(f"é‡å»ºæ•°æ®åº“ç»“æœ: {rebuild_success}")


if __name__ == "__main__":
    asyncio.run(main())